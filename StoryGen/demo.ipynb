{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b06e23",
   "metadata": {},
   "source": [
    "## Image Sequence to Story generation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d36e28",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b8300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import nltk\n",
    "import ipyplot\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932342f2",
   "metadata": {},
   "source": [
    "### 2. Read Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b3026fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data_example as either 'VIST' or 'COCO'. \n",
    "\n",
    "# For VIST, we sample a fixed image sequence from the VIST test dataset. \n",
    "# For COCO, we sample a random set of similar images from the MS-COCO test split (More diverse generations).\n",
    "\n",
    "data_example = 'VIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "373a32f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        #ipyplot-html-viewer-toggle-DMreW4kZ2UGwbDShGMAUFy {\n",
       "            position: absolute;\n",
       "            top: -9999px;\n",
       "            left: -9999px;\n",
       "            visibility: hidden;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-label-DMreW4kZ2UGwbDShGMAUFy { \n",
       "            position: relative;\n",
       "            display: inline-block;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-textarea-DMreW4kZ2UGwbDShGMAUFy {\n",
       "            background: lightgrey;\n",
       "            width: 100%;\n",
       "            height: 0px;\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-DMreW4kZ2UGwbDShGMAUFy:checked ~ #ipyplot-html-viewer-textarea-DMreW4kZ2UGwbDShGMAUFy {\n",
       "            height: 200px;\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        #ipyplot-html-viewer-toggle-DMreW4kZ2UGwbDShGMAUFy:checked + #ipyplot-html-viewer-label-DMreW4kZ2UGwbDShGMAUFy:after {\n",
       "            content: \"hide html\";\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            right: 0;\n",
       "            bottom: 0;\n",
       "            background: white;\n",
       "            cursor: pointer;\n",
       "            color: blue;\n",
       "            text-decoration: underline;\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <input type=\"checkbox\" id=\"ipyplot-html-viewer-toggle-DMreW4kZ2UGwbDShGMAUFy\">\n",
       "        <label id=\"ipyplot-html-viewer-label-DMreW4kZ2UGwbDShGMAUFy\" for=\"ipyplot-html-viewer-toggle-DMreW4kZ2UGwbDShGMAUFy\">show html</label>\n",
       "        <textarea id=\"ipyplot-html-viewer-textarea-DMreW4kZ2UGwbDShGMAUFy\" readonly>\n",
       "            \n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 180px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 180px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp img {\n",
       "            width: 180px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-CfxbG7b6BCL4uCxhfEFngh\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000249184.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000249184.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-CfxbG7b6BCL4uCxhfEFngh\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-PjTZn5usTSrcvXJg5YkFKV\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">1</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000575222.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000575222.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-PjTZn5usTSrcvXJg5YkFKV\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-82hqydHdjkcgebGWSQ8DYA\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">2</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000574703.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000574703.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-82hqydHdjkcgebGWSQ8DYA\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-iEMPkngZgLo8SB5umtiKUF\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">3</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000404297.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000404297.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-iEMPkngZgLo8SB5umtiKUF\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-7H4LUMinmntM3Xn6txf6D3\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">4</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000567013.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000567013.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-7H4LUMinmntM3Xn6txf6D3\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>\n",
       "        </textarea>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "        #ipyplot-imgs-container-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            margin: 0%;\n",
       "            overflow: auto;\n",
       "            position: relative;\n",
       "            overflow-y: scroll;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 180px;\n",
       "            display: inline-block;\n",
       "            margin: 3px;\n",
       "            position: relative;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp {\n",
       "            width: 180px;\n",
       "            background: white;\n",
       "            display: inline-block;\n",
       "            vertical-align: top;\n",
       "            text-align: center;\n",
       "            position: relative;\n",
       "            border: 2px solid #ddd;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-close {\n",
       "            display: none;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span {\n",
       "            width: 100%;\n",
       "            height: 100%;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp img {\n",
       "            width: 180px;\n",
       "        }\n",
       "\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-close:hover {\n",
       "            cursor: zoom-out;\n",
       "        }\n",
       "        div.ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp span.ipyplot-img-expand:hover {\n",
       "            cursor: zoom-in;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target {\n",
       "            transform: scale(2.5);\n",
       "            transform-origin: left top;\n",
       "            z-index: 5000;\n",
       "            top: 0;\n",
       "            left: 0;\n",
       "            position: absolute;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target span.ipyplot-img-close {\n",
       "            display: block;\n",
       "        }\n",
       "\n",
       "        div[id^=ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp]:target span.ipyplot-img-expand {\n",
       "            display: none;\n",
       "        }\n",
       "        </style>\n",
       "    <div id=\"ipyplot-imgs-container-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-CfxbG7b6BCL4uCxhfEFngh\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">0</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000249184.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000249184.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-CfxbG7b6BCL4uCxhfEFngh\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-PjTZn5usTSrcvXJg5YkFKV\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">1</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000575222.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000575222.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-PjTZn5usTSrcvXJg5YkFKV\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-82hqydHdjkcgebGWSQ8DYA\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">2</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000574703.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000574703.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-82hqydHdjkcgebGWSQ8DYA\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-iEMPkngZgLo8SB5umtiKUF\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">3</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000404297.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000404297.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-iEMPkngZgLo8SB5umtiKUF\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    \n",
       "    <div class=\"ipyplot-placeholder-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "        <div id=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-7H4LUMinmntM3Xn6txf6D3\" class=\"ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp\">\n",
       "            <h4 style=\"font-size: 12px; word-wrap: break-word;\">4</h4>\n",
       "            <h4 style=\"font-size: 9px; padding-left: 10px; padding-right: 10px; width: 95%; word-wrap: break-word; white-space: normal;\">demo_utils/MSCOCO/CL1/COCO_val2014_000000567013.jpg</h4><img src=\"demo_utils/MSCOCO/CL1/COCO_val2014_000000567013.jpg\"/>\n",
       "            <a href=\"#!\">\n",
       "                <span class=\"ipyplot-img-close\"/>\n",
       "            </a>\n",
       "            <a href=\"#ipyplot-content-div-eZFa5ELfaJUMe9sMejSXrp-7H4LUMinmntM3Xn6txf6D3\">\n",
       "                <span class=\"ipyplot-img-expand\"/>\n",
       "            </a>\n",
       "        </div>\n",
       "    </div>\n",
       "    </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if data_example == 'VIST':\n",
    "    \n",
    "    # Path to generated Flickr Captions\n",
    "    flickr_gens = np.load('../pretrained/sub_gc_flickr/captions_16000.npy', allow_pickle=True)\n",
    "    \n",
    "    # Path to VIST Images\n",
    "    VIST_demo_path = 'demo_utils/VIST_Flickr'\n",
    "    VIST_demo_imgs = glob.glob(os.path.join(VIST_demo_path, '*.jpg'))\n",
    "    VIST_demo_ids = [os.path.basename(p).split('_')[0] for p in VIST_demo_imgs]\n",
    "\n",
    "    # Load Presaved Generations (with scores) from Ids\n",
    "    VIST_demo_generations = [[gen for gen in flickr_gens if str(gen['image_id']) == Id][0] for Id in VIST_demo_ids]\n",
    "\n",
    "    # Display Images\n",
    "    ipyplot.plot_images(VIST_demo_imgs, max_images=20, img_width=180)\n",
    "    \n",
    "    # Ground Truth Story (If Present)\n",
    "    with open('demo_utils/VIST_Flickr/ground_truth_story.txt') as f:\n",
    "        gtstory = f.read()\n",
    "    print(\"Ground Truth Story: {}\".format(gtstory))\n",
    "    \n",
    "    # Prepare Data\n",
    "    captions = VIST_demo_generations\n",
    "    \n",
    "elif data_example == 'COCO':\n",
    "    \n",
    "    # Path to generated MS-COCO Captions\n",
    "    coco_gens = np.load('../pretrained/sub_gc_MRNN/captions_60000.npy', allow_pickle=True)\n",
    "\n",
    "    # Path to MS-COCO Images\n",
    "    COCO_demo_dir = 'demo_utils/MSCOCO'\n",
    "    COCO_demo_path = random.sample(glob.glob(os.path.join(COCO_demo_dir, '*')), 1)[0]\n",
    "    COCO_demo_path = 'demo_utils/MSCOCO/CL1'\n",
    "    COCO_demo_imgs = glob.glob(os.path.join(COCO_demo_path, '*.jpg'))\n",
    "    COCO_demo_ids = [os.path.basename(p) for p in COCO_demo_imgs]\n",
    "\n",
    "    # Load Presaved Generations (with scores) from Ids\n",
    "    COCO_demo_generations = [[gen for gen in coco_gens if os.path.basename(gen['image_path']) == Id][0] for Id in COCO_demo_ids]\n",
    "\n",
    "    # Display Images\n",
    "    ipyplot.plot_images(COCO_demo_imgs, max_images=20, img_width=180)\n",
    "    \n",
    "    # Prepare Data\n",
    "    captions = COCO_demo_generations    \n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Data Split not recognised ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be5a56",
   "metadata": {},
   "source": [
    "### 3. Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba5e2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we load the C2S-LM model. \n",
    "# Sub-GC predictions are presaved locally and read along with data to prevent additional preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91c1a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file pretrained/t5-large-finetuned-caption-to-story-gen/checkpoint-5000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"pretrained/t5-large-finetuned-caption-to-story-gen/checkpoint-5000/\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pretrained/t5-large-finetuned-caption-to-story-gen/checkpoint-5000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at pretrained/t5-large-finetuned-caption-to-story-gen/checkpoint-5000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained C2S-LM\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_checkpoint = \"pretrained/t5-large-finetuned-caption-to-story-gen/checkpoint-5000/\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2aa6f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /home/bsantra/.cache/huggingface/hub/models--t5-large/snapshots/cb7a9673bcaf9ab8b677ad4a5650c1d74b4a5a8e/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading file spiece.model from cache at /home/bsantra/.cache/huggingface/hub/models--t5-large/snapshots/cb7a9673bcaf9ab8b677ad4a5650c1d74b4a5a8e/spiece.model\n",
      "loading file tokenizer.json from cache at /home/bsantra/.cache/huggingface/hub/models--t5-large/snapshots/cb7a9673bcaf9ab8b677ad4a5650c1d74b4a5a8e/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/bsantra/.cache/huggingface/hub/models--t5-large/snapshots/cb7a9673bcaf9ab8b677ad4a5650c1d74b4a5a8e/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "model_checkpoint = \"t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615d8ef2",
   "metadata": {},
   "source": [
    "### 4. Preprocess Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be3412ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a set of generated captions\n",
    "capset = [cap['caption'][0].capitalize()+'.' for cap in captions]\n",
    "data = [capset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df66db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of people standing around a field.',\n",
       " 'A small train is going down the track.',\n",
       " 'A large boat is traveling down the water.',\n",
       " 'A dog running in the grass with a frisbee.',\n",
       " 'A bus is driving down the street with a truck on the back.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57b4a500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-cb8e3eeabf632e75\n",
      "WARNING:datasets.builder:Found cached dataset generator (/home/bsantra/.cache/huggingface/datasets/generator/default-cb8e3eeabf632e75/0.0.0)\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/bsantra/.cache/huggingface/datasets/generator/default-cb8e3eeabf632e75/0.0.0/cache-d6bccf2391099cf9.arrow\n"
     ]
    }
   ],
   "source": [
    "def data_gen():\n",
    "    for i in range(len(data)):\n",
    "        yield {\"captions\": \" \".join(data[i]), \"story\": \"N.A.\"}\n",
    "        \n",
    "# Huggingface Dataset Object for one data-point\n",
    "dataset = Dataset.from_generator(data_gen)\n",
    "\n",
    "prefix = \"generate a short story using the following descriptions of events: \"\n",
    "max_input_length = 256\n",
    "max_target_length = 256\n",
    "\n",
    "def preprocess(datapoint):\n",
    "    inputs = [prefix + caption for caption in datapoint[\"captions\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(datapoint[\"story\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# inference_dataset\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f98061",
   "metadata": {},
   "source": [
    "### 5. Run C2S-LM on generated captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71ef83e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7034b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metric = load_metric(\"rouge\")\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61b34891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"pretrained/{model_checkpoint}-finetuned-caption-to-story-gen\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "    auto_find_batch_size=True,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset=tokenized_dataset, max_length = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5994cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Predicted Story #####\n",
      "The family was excited to go to the fair. The train was going to go down the track. The boat was going down the river. The dog was having fun. The bus was going down the street.\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions:\n",
    "    print(\"##### Predicted Story #####\")\n",
    "    print(tokenizer.decode(pred, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438c3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
