{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b94f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/graphml/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/bsantra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from pprint import pprint\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "RANDOM_SEED = 42\n",
    "seed_everything(RANDOM_SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1968b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd() != \"/home/bsantra/divyanshu/graphml/Sub-GC/\":\n",
    "    os.chdir(\"/home/bsantra/divyanshu/graphml/Sub-GC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f62af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/VIST/text/train/description_story_data.json\", 'r') as f1:\n",
    "    train_data = json.load(f1)\n",
    "with open(\"data/VIST/text/val/description_story_data.json\", \"r\") as f1:\n",
    "    val_data = json.load(f1)\n",
    "with open(\"data/VIST/text/test/description_story_data.json\", \"r\") as f1:\n",
    "    test_data = json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7edd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f04979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-500176f0b234ac10\n",
      "Found cached dataset generator (/home/bsantra/.cache/huggingface/datasets/generator/default-500176f0b234ac10/0.0.0)\n",
      "Using custom data configuration default-69cb9715e4684dba\n",
      "Found cached dataset generator (/home/bsantra/.cache/huggingface/datasets/generator/default-69cb9715e4684dba/0.0.0)\n",
      "Using custom data configuration default-18f4a3792d2f59e5\n",
      "Found cached dataset generator (/home/bsantra/.cache/huggingface/datasets/generator/default-18f4a3792d2f59e5/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "def train_data_gen():\n",
    "    for i in range(len(train_data)):\n",
    "        yield {\"captions\": \" \".join(train_data[i][0]), \"story\": \" \".join(train_data[i][1])}\n",
    "        \n",
    "def val_data_gen():\n",
    "    for i in range(len(val_data)):\n",
    "        yield {\"captions\": \" \".join(val_data[i][0]), \"story\": \" \".join(val_data[i][1])}\n",
    "\n",
    "def test_data_gen():\n",
    "    for i in range(len(test_data)):\n",
    "        yield {\"captions\": \" \".join(test_data[i][0]), \"story\": \" \".join(test_data[i][1])}\n",
    "        \n",
    "train_dataset = Dataset.from_generator(train_data_gen)\n",
    "val_dataset = Dataset.from_generator(val_data_gen)\n",
    "test_dataset = Dataset.from_generator(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "638ca93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"generate a short story using the following descriptions of events: \"\n",
    "max_input_length = 256\n",
    "max_target_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3cd75cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(datapoint):\n",
    "    inputs = [prefix + caption for caption in datapoint[\"captions\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(datapoint[\"story\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde592d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/65 [00:00<?, ?ba/s]/home/bsantra/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3542: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:06<00:00,  9.58ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.49ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.83ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(preprocess, batched=True)\n",
    "tokenized_val = val_dataset.map(preprocess, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d251d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our landmark tree in town was about to be destroyed and cleared for a new mall.  So we decided to take the day to go out and enjoy its beauty. To see the final glimpse of the roots, extending out into the depths of the hill. And its magnificent trunk, larger than life itself. One last picture of its beauty so we could capture it forever. '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[0][\"story\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "360abb94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our landmark tree in town was about to be destroyed and cleared for a new mall. So we decided to take the day to go out and enjoy its beauty. To see the final glimpse of the roots, extending out into the depths of the hill. And its magnificent trunk, larger than life itself. One last picture of its beauty so we could capture it forever.</s>'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_train[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33f8991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.</s>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_test[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11261f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dde8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 6\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-caption-to-story-gen\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "    auto_find_batch_size=True,\n",
    "    weight_decay=0.01,\n",
    "#     save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    report_to=\"none\",\n",
    "#     push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7dfbd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138923/3314070117.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c20845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5982fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f21d6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf758928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsantra/miniconda3/envs/graphml/lib/python3.10/site-packages/accelerate/memory_utils.py:23: FutureWarning: memory_utils has been reorganized to utils.memory. Import `find_executable_batchsize` from the main `__init__`: `from accelerate import find_executable_batch_size` to avoid this warning.\n",
      "  warnings.warn(\n",
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/bsantra/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 64248\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8031\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8031' max='8031' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8031/8031 2:12:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.843500</td>\n",
       "      <td>2.709251</td>\n",
       "      <td>19.984200</td>\n",
       "      <td>3.251500</td>\n",
       "      <td>15.571800</td>\n",
       "      <td>18.935500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.798600</td>\n",
       "      <td>2.672272</td>\n",
       "      <td>20.185100</td>\n",
       "      <td>3.701500</td>\n",
       "      <td>15.751900</td>\n",
       "      <td>19.188800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.778100</td>\n",
       "      <td>2.656246</td>\n",
       "      <td>20.061400</td>\n",
       "      <td>3.668400</td>\n",
       "      <td>15.523500</td>\n",
       "      <td>19.046100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.745900</td>\n",
       "      <td>2.645715</td>\n",
       "      <td>20.065400</td>\n",
       "      <td>3.710300</td>\n",
       "      <td>15.540100</td>\n",
       "      <td>19.094900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.749200</td>\n",
       "      <td>2.637733</td>\n",
       "      <td>20.034700</td>\n",
       "      <td>3.603900</td>\n",
       "      <td>15.475900</td>\n",
       "      <td>19.055100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.737900</td>\n",
       "      <td>2.631223</td>\n",
       "      <td>20.035700</td>\n",
       "      <td>3.596800</td>\n",
       "      <td>15.509700</td>\n",
       "      <td>19.060200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.718900</td>\n",
       "      <td>2.628633</td>\n",
       "      <td>20.103700</td>\n",
       "      <td>3.568400</td>\n",
       "      <td>15.469700</td>\n",
       "      <td>19.114000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.747000</td>\n",
       "      <td>2.627229</td>\n",
       "      <td>20.104500</td>\n",
       "      <td>3.529500</td>\n",
       "      <td>15.517100</td>\n",
       "      <td>19.112000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-1000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-1000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-2000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-2000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-3000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-3000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-4000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-4000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-4000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-5000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-5000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-5000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-6000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-6000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-6000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-7000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-7000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-7000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7984\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to t5-large-finetuned-caption-to-story-gen/checkpoint-8000\n",
      "Configuration saved in t5-large-finetuned-caption-to-story-gen/checkpoint-8000/config.json\n",
      "Model weights saved in t5-large-finetuned-caption-to-story-gen/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in t5-large-finetuned-caption-to-story-gen/checkpoint-8000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8031, training_loss=2.776612090019461, metrics={'train_runtime': 7921.5716, 'train_samples_per_second': 8.111, 'train_steps_per_second': 1.014, 'total_flos': 2.714360389632e+16, 'train_loss': 2.776612090019461, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b13bd24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./t5-large-finetuned-caption-to-story-gen/checkpoint-5000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"./t5-large-finetuned-caption-to-story-gen/checkpoint-5000/\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 4096,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file ./t5-large-finetuned-caption-to-story-gen/checkpoint-5000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ./t5-large-finetuned-caption-to-story-gen/checkpoint-5000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"./t5-large-finetuned-caption-to-story-gen/checkpoint-5000/\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e1af911",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9de7ee1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: story, captions. If story, captions are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 8088\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, label_ids, metrics = trainer.predict(test_dataset=tokenized_test, max_length = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "084c0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(tokenized_test[0][\"input_ids\"]).to(DEVICE)\n",
    "attn_mask = torch.tensor(tokenized_test[0][\"attention_mask\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af42b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'captions': 'The sign is describing when the services will begin. Sitting there waiting on someone to come over and buy something. a case full of books in a house, books appear to be old A older man with a black hat, mustache and glasses. A man in a top hat has a magic trick on the floor.',\n",
       " 'story': 'The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.',\n",
       " 'input_ids': [3806,\n",
       "  3,\n",
       "  9,\n",
       "  710,\n",
       "  733,\n",
       "  338,\n",
       "  8,\n",
       "  826,\n",
       "  15293,\n",
       "  13,\n",
       "  984,\n",
       "  10,\n",
       "  37,\n",
       "  1320,\n",
       "  19,\n",
       "  3,\n",
       "  16012,\n",
       "  116,\n",
       "  8,\n",
       "  364,\n",
       "  56,\n",
       "  1731,\n",
       "  5,\n",
       "  925,\n",
       "  6031,\n",
       "  132,\n",
       "  2794,\n",
       "  30,\n",
       "  841,\n",
       "  12,\n",
       "  369,\n",
       "  147,\n",
       "  11,\n",
       "  805,\n",
       "  424,\n",
       "  5,\n",
       "  3,\n",
       "  9,\n",
       "  495,\n",
       "  423,\n",
       "  13,\n",
       "  1335,\n",
       "  16,\n",
       "  3,\n",
       "  9,\n",
       "  629,\n",
       "  6,\n",
       "  1335,\n",
       "  2385,\n",
       "  12,\n",
       "  36,\n",
       "  625,\n",
       "  71,\n",
       "  2749,\n",
       "  388,\n",
       "  28,\n",
       "  3,\n",
       "  9,\n",
       "  1001,\n",
       "  3,\n",
       "  547,\n",
       "  6,\n",
       "  398,\n",
       "  4933,\n",
       "  11,\n",
       "  9832,\n",
       "  5,\n",
       "  71,\n",
       "  388,\n",
       "  16,\n",
       "  3,\n",
       "  9,\n",
       "  420,\n",
       "  3,\n",
       "  547,\n",
       "  65,\n",
       "  3,\n",
       "  9,\n",
       "  5189,\n",
       "  7873,\n",
       "  30,\n",
       "  8,\n",
       "  1501,\n",
       "  5,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [37,\n",
       "  415,\n",
       "  14961,\n",
       "  4532,\n",
       "  3,\n",
       "  9,\n",
       "  5449,\n",
       "  504,\n",
       "  284,\n",
       "  215,\n",
       "  5,\n",
       "  14868,\n",
       "  13,\n",
       "  5265,\n",
       "  369,\n",
       "  91,\n",
       "  11,\n",
       "  356,\n",
       "  95,\n",
       "  5056,\n",
       "  12,\n",
       "  1789,\n",
       "  70,\n",
       "  11109,\n",
       "  5,\n",
       "  886,\n",
       "  13,\n",
       "  175,\n",
       "  11109,\n",
       "  33,\n",
       "  182,\n",
       "  775,\n",
       "  11,\n",
       "  240,\n",
       "  3,\n",
       "  9,\n",
       "  418,\n",
       "  13,\n",
       "  3683,\n",
       "  12,\n",
       "  143,\n",
       "  5,\n",
       "  19848,\n",
       "  7,\n",
       "  13,\n",
       "  66,\n",
       "  3,\n",
       "  2568,\n",
       "  369,\n",
       "  91,\n",
       "  12,\n",
       "  399,\n",
       "  1074,\n",
       "  8,\n",
       "  11109,\n",
       "  21,\n",
       "  1048,\n",
       "  5,\n",
       "  886,\n",
       "  13,\n",
       "  8,\n",
       "  5449,\n",
       "  277,\n",
       "  237,\n",
       "  3270,\n",
       "  95,\n",
       "  16,\n",
       "  775,\n",
       "  18003,\n",
       "  38,\n",
       "  294,\n",
       "  13,\n",
       "  70,\n",
       "  3014,\n",
       "  1810,\n",
       "  5,\n",
       "  1]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c4651427",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1611\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1611\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1621\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1622\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1623\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1624\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1625\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:943\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m--> 943\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# required mask seq length can be calculated via length of past\u001b[39;00m\n\u001b[1;32m    946\u001b[0m mask_seq_length \u001b[38;5;241m=\u001b[39m past_key_values[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m seq_length \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m seq_length\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d6bef04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(tokenized_test[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1611\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1611\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1621\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1622\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1623\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1624\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1625\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/graphml/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:943\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m--> 943\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# required mask seq length can be calculated via length of past\u001b[39;00m\n\u001b[1;32m    946\u001b[0m mask_seq_length \u001b[38;5;241m=\u001b[39m past_key_values[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m seq_length \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m seq_length\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor(tokenized_test[0][\"input_ids\"]).to(DEVICE)\n",
    "outputs = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40b045a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   37   415 14961  4532     3     9  5449   504   284   215     5 14868\n",
      "    13  5265   369    91    11   356    95  5056    12  1789    70 11109\n",
      "     5   886    13   175 11109    33   182   775    11   240     3     9\n",
      "   418    13  3683    12   143     5 19848     7    13    66     3  2568\n",
      "   369    91    12   399  1074     8 11109    21  1048     5   886    13\n",
      "     8  5449   277   237  3270    95    16   775 18003    38   294    13\n",
      "    70  3014  1810     5     1]\n"
     ]
    }
   ],
   "source": [
    "labels_here = np.array([k for k in label_ids[0] if k != -100])\n",
    "print(labels_here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3d960f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0   37 2078   47    3    9  248  286   12  719    5   37  151  130\n",
      "  182 2609    5   37 1335  130]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8546a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenp = []\n",
    "for p in predictions:\n",
    "    lenp.append(len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f807524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#1\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The people were very friendly. The books were very old. The man was very funny. He was very good at magic.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.\n",
      "\n",
      "\n",
      "#2\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were displayed on the table. The books were on the ground. The man was talking to the people. The man was seated on the floor.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.\n",
      "\n",
      "\n",
      "#3\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The people were very friendly. The books were very old. The man was very funny. He was very good at magic.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "I was so excited to be heading to the crafts fair. When I arrived I saw a great booth with a variety of great crafts. I stopped at chatted at my friend Beth's booth for a bit. There were even booths set up for all of the kids. I found some awesome crafts at the fair, I'm really happy that I went.\n",
      "\n",
      "\n",
      "#4\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were displayed on the table. The books were on the ground. The man was talking to the people. The man was seated on the floor.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "I was so excited to be heading to the crafts fair. When I arrived I saw a great booth with a variety of great crafts. I stopped at chatted at my friend Beth's booth for a bit. There were even booths set up for all of the kids. I found some awesome crafts at the fair, I'm really happy that I went.\n",
      "\n",
      "\n",
      "#5\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The people were very friendly. The books were very old. The man was very funny. He was very good at magic.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The church is old, but it has a nice history. They display this history during the afternoon. Some books even talk about Africa. The older members of the church remember these things. It makes them sad.\n",
      "\n",
      "\n",
      "#6\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were displayed on the table. The books were on the ground. The man was talking to the people. The man was seated on the floor.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The church is old, but it has a nice history. They display this history during the afternoon. Some books even talk about Africa. The older members of the church remember these things. It makes them sad.\n",
      "\n",
      "\n",
      "#7\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The people were very friendly. The books were very old. The man was very funny. He was very good at magic.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The people arrived to get ready for the craft fair. The various merchants set up their booths. The different merchants got together to talk before people began to arrive. Even the kids got to make some crafts. Everyone is set up and ready for the craft fair.\n",
      "\n",
      "\n",
      "#8\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were displayed on the table. The books were on the ground. The man was talking to the people. The man was seated on the floor.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The people arrived to get ready for the craft fair. The various merchants set up their booths. The different merchants got together to talk before people began to arrive. Even the kids got to make some crafts. Everyone is set up and ready for the craft fair.\n",
      "\n",
      "\n",
      "#9\n",
      "##### Predicted Story #####\n",
      "The girls were excited to go to the carnival. They were excited to ride the roller coaster. They were so excited to ride the dragon roller coaster. They loved the stuffed apes. They were so excited to play the games.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The family takes a trip to the local carnival. There are lots of rides to enjoy this year. There are even rides for folks as young as this small boy. There are also lots of games and prizes to win. Although some of the games seem fixed and a waste of money.\n",
      "\n",
      "\n",
      "#10\n",
      "##### Predicted Story #####\n",
      "The kids were excited to go to the amusement park. They rode the roller coaster. They also saw the monkeys. They also played darts. They had a great time.\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The family takes a trip to the local carnival. There are lots of rides to enjoy this year. There are even rides for folks as young as this small boy. There are also lots of games and prizes to win. Although some of the games seem fixed and a waste of money.\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for each in label_ids:\n",
    "    labels_here = np.array([k for k in each if k != -100])\n",
    "    labels.append(labels_here)\n",
    "\n",
    "i = 0\n",
    "for pred, label in zip(predictions[:10], labels[:10]):\n",
    "    i += 1\n",
    "    print(f\"\\n\\n#{i}\")\n",
    "    print(\"##### Predicted Story #####\")\n",
    "    print(tokenizer.decode(pred, skip_special_tokens=True))\n",
    "    print(\"\\n##### Ground Truth Story #####\")\n",
    "    print(tokenizer.decode(label, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7521318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#1\n",
      "##### Predicted Story #####\n",
      "The family went to the library to get some books. They were able to get some books\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.\n",
      "\n",
      "\n",
      "#2\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were very interesting. The books were\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.\n",
      "\n",
      "\n",
      "#3\n",
      "##### Predicted Story #####\n",
      "The family went to the library to get some books. They were able to get some books\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "I was so excited to be heading to the crafts fair. When I arrived I saw a great booth with a variety of great crafts. I stopped at chatted at my friend Beth's booth for a bit. There were even booths set up for all of the kids. I found some awesome crafts at the fair, I'm really happy that I went.\n",
      "\n",
      "\n",
      "#4\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were very interesting. The books were\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "I was so excited to be heading to the crafts fair. When I arrived I saw a great booth with a variety of great crafts. I stopped at chatted at my friend Beth's booth for a bit. There were even booths set up for all of the kids. I found some awesome crafts at the fair, I'm really happy that I went.\n",
      "\n",
      "\n",
      "#5\n",
      "##### Predicted Story #####\n",
      "The family went to the library to get some books. They were able to get some books\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The church is old, but it has a nice history. They display this history during the afternoon. Some books even talk about Africa. The older members of the church remember these things. It makes them sad.\n",
      "\n",
      "\n",
      "#6\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were very interesting. The books were\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The church is old, but it has a nice history. They display this history during the afternoon. Some books even talk about Africa. The older members of the church remember these things. It makes them sad.\n",
      "\n",
      "\n",
      "#7\n",
      "##### Predicted Story #####\n",
      "The family went to the library to get some books. They were able to get some books\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The people arrived to get ready for the craft fair. The various merchants set up their booths. The different merchants got together to talk before people began to arrive. Even the kids got to make some crafts. Everyone is set up and ready for the craft fair.\n",
      "\n",
      "\n",
      "#8\n",
      "##### Predicted Story #####\n",
      "The church was a great place to visit. The cards were very interesting. The books were\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The people arrived to get ready for the craft fair. The various merchants set up their booths. The different merchants got together to talk before people began to arrive. Even the kids got to make some crafts. Everyone is set up and ready for the craft fair.\n",
      "\n",
      "\n",
      "#9\n",
      "##### Predicted Story #####\n",
      "The girls were excited to go to the carnival. They were excited to ride the roller coaster\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The family takes a trip to the local carnival. There are lots of rides to enjoy this year. There are even rides for folks as young as this small boy. There are also lots of games and prizes to win. Although some of the games seem fixed and a waste of money.\n",
      "\n",
      "\n",
      "#10\n",
      "##### Predicted Story #####\n",
      "The kids were excited to go to the amusement park. They rode the roller coaster\n",
      "\n",
      "##### Ground Truth Story #####\n",
      "The family takes a trip to the local carnival. There are lots of rides to enjoy this year. There are even rides for folks as young as this small boy. There are also lots of games and prizes to win. Although some of the games seem fixed and a waste of money.\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for each in label_ids:\n",
    "    labels_here = np.array([k for k in each if k != -100])\n",
    "    labels.append(labels_here)\n",
    "\n",
    "i = 0\n",
    "for pred, label in zip(predictions[:10], labels[:10]):\n",
    "    i += 1\n",
    "    print(f\"\\n\\n#{i}\")\n",
    "    print(\"##### Predicted Story #####\")\n",
    "    print(tokenizer.decode(pred, skip_special_tokens=True))\n",
    "    print(\"\\n##### Ground Truth Story #####\")\n",
    "    print(tokenizer.decode(label, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = np.array([k for k in label_ids[0] if k != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccd92052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The local parish holds a craft show each year. Lots of folks come out and set up tables to sell their crafts. Some of these crafts are very unique and take a lot of talent to make. Folks of all ages come out to peruse the crafts for sale. Some of the crafters even dress up in unique costumes as part of their selling act.</s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
